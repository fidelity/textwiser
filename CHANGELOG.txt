=====================
TextWiser CHANGELOG
=====================

-------------------------------------------------------------------------------
Feb 03, 2023 1.5.1
-------------------------------------------------------------------------------
minor:
- Enable easy pickling of textwiser objects by explicitly setting model download locations for all relevant libraries

-------------------------------------------------------------------------------
Dec 19, 2022 1.5.0
-------------------------------------------------------------------------------
major:
- Utilize ELMo from TFHub and remove allennlp dependency

-------------------------------------------------------------------------------
Mar 03, 2022 1.4.0
-------------------------------------------------------------------------------
major:
- Update UMAP to return deterministic output in latest version
  Source: https://github.com/fidelity/textwiser/blob/39bad042104c41d0d57174b49941882af79cc3db/textwiser/transformations/umap_.py#L23
- Update SVD to return deterministic output
  Source: https://github.com/fidelity/textwiser/blob/39bad042104c41d0d57174b49941882af79cc3db/textwiser/transformations/svd.py#L26
- Update Word2Vec and Doc2Vec with latest gensim training
  Source: https://github.com/fidelity/textwiser/blob/39bad042104c41d0d57174b49941882af79cc3db/textwiser/embeddings/word.py#L204
  Source: https://github.com/fidelity/textwiser/blob/39bad042104c41d0d57174b49941882af79cc3db/textwiser/embeddings/doc2vec.py#L25

minor:
- Disable non-relevant transformers warning
- Add full requirement install option (see requirements_full.txt)
- Make gensim requirement explicit instead of relying on flair's dependency tree
- Directly utilize ELMo from allennlp instead of flair by bumping allennlp requirement

-------------------------------------------------------------------------------
Feb 23, 2022 1.3.2
-------------------------------------------------------------------------------
minor:
- Added upper bound for flair (less or equal to 0.9) to pass python3.9 unit tests

-------------------------------------------------------------------------------
Jan 21, 2021 1.3.1
-------------------------------------------------------------------------------
minor:
- Updated dependency requirements to reflect updates to Flair library

-------------------------------------------------------------------------------
Jul 22, 2020 1.3.0
-------------------------------------------------------------------------------
major:
- Added T5, XLM-RoBERTa, BART, ECELTRA, DialoGPT, Longformer embeddings
- Added inline pooling for Word embeddings to make some pooling scenarios faster

minor:
- Updated basic usage notebook
- Updated preferred method of persistence & examples
- SVD now properly appears in model parameters and can be fine-tuned

-------------------------------------------------------------------------------
Mar 12, 2020 1.2.1
-------------------------------------------------------------------------------

minor:
- Fix transformers model initialization for newer versions of transformers

-------------------------------------------------------------------------------
Feb 13, 2020 1.2.0
-------------------------------------------------------------------------------
major:
- Update Universal Sentence Encoder
  - Now works with newer versions
  - Default version is now v5
- Add bytepair embeddings
- Add ALBERT embeddings

minor:
- Add explicit fit_transform method to Compound embeddings to make them faster

-------------------------------------------------------------------------------
Nov 13, 2019 1.1.1
-------------------------------------------------------------------------------

minor:
- Fix running transformers models on a GPU
- Fix modification of input schema object for Compound embeddings

-------------------------------------------------------------------------------
Oct 24, 2019 1.1.0
-------------------------------------------------------------------------------

major:
- All transformer-based models are powered by the transformers library
  - This enables fine-tuning for transformer models!
  - There isn't a subword to word level aggregation, everything is aggregated at doc level
  - The models output the last layer by default
  - The scalar mix parameter is discontinued
- Add DistilBERT and CTRL models
- Add Sphinx documentation
- Add LICENSE

minor:
- More modular word embedding testing

-------------------------------------------------------------------------------
Oct 3, 2019 1.0.1
-------------------------------------------------------------------------------

major:
- Data in different structures are only converted to torch tensor if necessary (major speedup for sklearn models!)

minor:
- Fix word2vec fit behavior to match other trainable models
- Add explicit fit_transform to TextWiser for faster inference with sklearn models

-------------------------------------------------------------------------------
Sept 27, 2019 1.0.0
-------------------------------------------------------------------------------

- Initial release.

-------------------------------------------------------------------------------
July 29, 2019 0.0.1
-------------------------------------------------------------------------------

- Development starts. Unstable.
